{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы взялись исследовать криптовалюты. Для начала краткий дайвинг в получение и работу с данными по криптовалютам разных бирж. Основной источник:\n",
    "https://blog.patricktriest.com/analyzing-cryptocurrencies-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import quandl\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quandl_data(quandl_id):\n",
    "    '''Download and cache Quandl dataseries'''\n",
    "    cache_path = '{}.pkl'.format(quandl_id).replace('/','-')\n",
    "    try:\n",
    "        f = open(cache_path, 'rb')\n",
    "        df = pickle.load(f)   \n",
    "        print('Loaded {} from cache'.format(quandl_id))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {} from Quandl'.format(quandl_id))\n",
    "        df = quandl.get(quandl_id, returns=\"pandas\")\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(quandl_id, cache_path))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Kraken BTC price exchange data\n",
    "btc_usd_price_kraken = get_quandl_data('BCHARTS/KRAKENUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usd_price_kraken.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usd_price_kraken.tail()['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usd_price_kraken.tail()['Open'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usd_price_kraken.tail()['Open'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_usd_price_kraken.resample('W')['Open'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "btc_usd_price_kraken.tail()['Open'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak = btc_usd_price_kraken.resample('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter(x=btc_usd_price_kraken.resample('W')['Open'].mean().index,y=btc_usd_price_kraken.resample('W')['Open'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot([trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо, с данными уже можно работать. Попробуем получить БПФ от сигнала котировок биткойна. Для начала разберёмся со scipy чтобы считать БПФ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.fft(btc_usd_price_kraken['Weighted Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = scipy.fft(btc_usd_price_kraken.loc['2017-Aug':'2018-Aug','Weighted Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (fft_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absd = abs(fft_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot([go.Scatter(y=absd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [math.sin(2*math.pi*4*i/256) for i in range(0,256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.fft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot([go.Scatter(y=abs(data[:-int(data.size/2)]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, всё понятно, получили заветную синусоиду, с нормировкой разберёмся далее.\n",
    "А пока используем данные для частотного анализа по бирже Kraken..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = btc_usd_price_kraken.loc['2013-Aug':'2018-Aug','Weighted Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wSize=32\n",
    "wSize2 = int(wSize/2)\n",
    "freqMaxIdx=8\n",
    "\n",
    "# расчёт периодов сигналов котировок\n",
    "fs=1 #1day inverse\n",
    "f0=fs/wSize\n",
    "deltaF=fs/(2*wSize)\n",
    "\n",
    "frame = data[0:wSize]\n",
    "window = blackman(wSize)\n",
    "m = array([abs(np.fft.fft(frame*window)/wSize)[:freqMaxIdx]])\n",
    "d = [data.index[wSize]]\n",
    "summ = []\n",
    "summ.append(sum(m[0]))\n",
    "\n",
    "# здесь он продолжается...\n",
    "per = []\n",
    "for j in range(0,wSize):\n",
    "     per.append(str(int(floor(1/(f0+j*deltaF))))+'​') #dirty hack U+200B invisible word delimeter =) plotly вредный, перемасштабирует график, а это нам не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,data.size-wSize):\n",
    "    frame = data[i:i+wSize]\n",
    "    window =blackman(wSize) # окно Блэкмана\n",
    "    m = append(m,[abs(np.fft.fft(frame*window)/wSize)[:freqMaxIdx]],0) #использую numpy ибо значения нормированные возращает в отличие от scipy\n",
    "    summ.append(sum(m[i]))\n",
    "    d.append(data.index[i+wSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = go.Heatmap(\n",
    "    z=m.transpose(),\n",
    "    x=d,\n",
    "    y=per,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    title='Fourier decomposition of BTC quotes (USD) [Kraken]',\n",
    "    titlefont=dict(\n",
    "        family='Courier New, monospace',\n",
    "        size=22,\n",
    "        color='#7f7f7f'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Period, days',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Date',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=[heatmap], layout=layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот здесь по-подробнее, ибо в этом графике вся соль и суть работы. Мы имеем разложение по гармоникам графика курса биткойна на бирже Kraken. Видно, что основные колебания происходят периодом около месяца, и что интересно, возможно намечается новая волна на повышение курса (правый нижний угол). Все остальные гармоники имеют меньшие амплитуды, но в тоже время можно увидеть появление и исчезание колебаний на нижних частотах. Если делать преобразование более точным по частоте, то вырисовываются более чёткие частотные линии. К ним я ещё вернусь, но их нужно верифицировать. Неясно, являются ли они реальными или это следствие принципа неопределённости. Хорошо бы было бы увеличить точность по частоте и по времени одновременно, но для этого нужны более точные исходные данные. Нужно будет заняться этим вопросом. Пока резюме - нужны дополнительные исследования связи появления гармоник с новостями, а также расширение исследований на другие валюты и биржи.\n",
    "\n",
    "Идея: основная задача - научиться прогнозировать частоты, тогда можно создать поличастотного бота иили вебсервис по продаже советов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot([go.Scatter(y=summ)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, видно, что сигнал оконный хорошо сглажен окном Блэкмана и обрабатываем мы не лажу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot([go.Scatter(x=data.index,y=data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=blackman(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.absolute(1 + 1j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.absolute(2 + 0j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(0+ 2j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хаха, модуль работает правильно!\n",
    "\n",
    "Теперь мы хотим получить VAR величину и закоррелировать её с хэшрейтами для опеределения влияния хэшрейтов на величину VAR.\n",
    "\n",
    "(https://ru.wikipedia.org/wiki/Value_At_Risk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим данные по иным криптовалютам с биржи Poloniex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_data(json_url, cache_path):\n",
    "    '''Download and cache JSON data, return as a dataframe.'''\n",
    "    try:        \n",
    "        f = open(cache_path, 'rb')\n",
    "        df = pickle.load(f)   \n",
    "        print('Loaded {} from cache'.format(json_url))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {}'.format(json_url))\n",
    "        df = pd.read_json(json_url)\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(json_url, cache_path))\n",
    "    return df\n",
    "\n",
    "base_polo_url = 'https://poloniex.com/public?command=returnChartData&currencyPair={}&start={}&end={}&period={}'\n",
    "start_date = datetime.strptime('2015-01-01', '%Y-%m-%d') # get data from the start of 2015\n",
    "end_date = datetime.now() # up until today\n",
    "pediod = 86400 # pull daily data (86,400 seconds per day)\n",
    "\n",
    "def get_crypto_data(poloniex_pair):\n",
    "    '''Retrieve cryptocurrency data from poloniex'''\n",
    "    json_url = base_polo_url.format(poloniex_pair, start_date.timestamp(), end_date.timestamp(), pediod)\n",
    "    data_df = get_json_data(json_url, poloniex_pair)\n",
    "    data_df = data_df.set_index('date')\n",
    "    return data_df\n",
    "\n",
    "altcoins = ['ETH','LTC','XRP','ETC','STR','DASH','SC','XMR','XEM']\n",
    "\n",
    "altcoin_data = {}\n",
    "for altcoin in altcoins:\n",
    "    coinpair = 'BTC_{}'.format(altcoin)\n",
    "    crypto_price_df = get_crypto_data(coinpair)\n",
    "    altcoin_data[altcoin] = crypto_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altcoin_data['ETH'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь цены выражены в биткойнах.\n",
    "\n",
    "Получим курсы BTC с других криптобирж, а потом усредним и получим цены ны альткойны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pricing data for 3 more BTC exchanges\n",
    "exchanges = ['COINBASE','BITSTAMP','ITBIT']\n",
    "\n",
    "exchange_data = {}\n",
    "\n",
    "exchange_data['KRAKEN'] = btc_usd_price_kraken\n",
    "\n",
    "for exchange in exchanges:\n",
    "    exchange_code = 'BCHARTS/{}USD'.format(exchange)\n",
    "    btc_exchange_df = get_quandl_data(exchange_code)\n",
    "    exchange_data[exchange] = btc_exchange_df\n",
    "    \n",
    "def merge_dfs_on_column(dataframes, labels, col):\n",
    "    '''Merge a single column of each dataframe into a new combined dataframe'''\n",
    "    series_dict = {}\n",
    "    for index in range(len(dataframes)):\n",
    "        series_dict[labels[index]] = dataframes[index][col]\n",
    "    return pd.DataFrame(series_dict)\n",
    "\n",
    "# Merge the BTC price dataseries' into a single dataframe\n",
    "btc_usd_datasets = merge_dfs_on_column(list(exchange_data.values()), list(exchange_data.keys()), 'Weighted Price')\n",
    "\n",
    "# Calculate the average BTC price as a new column\n",
    "btc_usd_datasets['avg_btc_price_usd'] = btc_usd_datasets.mean(axis=1)\n",
    "\n",
    "# Calculate USD Price as a new column in each altcoin dataframe\n",
    "for altcoin in altcoin_data.keys():\n",
    "    altcoin_data[altcoin]['price_usd'] =  altcoin_data[altcoin]['weightedAverage'] * btc_usd_datasets['avg_btc_price_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше повторяю действия из статьи, чтобы посмотреть на совместные колебания курсов криптовалют. Очень интересно: последний год колебания курсов сильно коррелируют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge USD price of each altcoin into single dataframe \n",
    "combined_df = merge_dfs_on_column(list(altcoin_data.values()), list(altcoin_data.keys()), 'price_usd')\n",
    "# Add BTC price to the dataframe\n",
    "combined_df['BTC'] = btc_usd_datasets['avg_btc_price_usd']\n",
    "# Calculate the pearson correlation coefficients for cryptocurrencies in 2016\n",
    "combined_df_2018 = combined_df[combined_df.index.year == 2018]\n",
    "combined_df_2018.pct_change().corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_scatter(df, title, seperate_y_axis=False, y_axis_label='', scale='linear', initial_hide=False):\n",
    "    '''Generate a scatter plot of the entire dataframe'''\n",
    "    label_arr = list(df)\n",
    "    series_arr = list(map(lambda col: df[col], label_arr))\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        legend=dict(orientation=\"h\"),\n",
    "        xaxis=dict(type='date'),\n",
    "        yaxis=dict(\n",
    "            title=y_axis_label,\n",
    "            showticklabels= not seperate_y_axis,\n",
    "            type=scale\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    y_axis_config = dict(\n",
    "        overlaying='y',\n",
    "        showticklabels=False,\n",
    "        type=scale )\n",
    "        \n",
    "    # Form Trace For Each Series\n",
    "    trace_arr = []\n",
    "    for index, series in enumerate(series_arr):\n",
    "        trace = go.Scatter(\n",
    "            x=series.index, \n",
    "            y=series, \n",
    "            name=label_arr[index],\n",
    "        )\n",
    "        \n",
    "        # Add seperate axis for the series\n",
    "        if seperate_y_axis:\n",
    "            trace['yaxis'] = 'y{}'.format(index + 1)\n",
    "            layout['yaxis{}'.format(index + 1)] = y_axis_config    \n",
    "        trace_arr.append(trace)\n",
    "\n",
    "    fig = go.Figure(data=trace_arr, layout=layout)\n",
    "    py.iplot(fig)\n",
    "\n",
    "# Chart all of the altocoin prices\n",
    "df_scatter(combined_df, 'Cryptocurrency Prices (USD)', seperate_y_axis=False, y_axis_label='Coin Value (USD)', scale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим простейший случай равнодолевого портфеля из койнов разных видов. Посчитаем величину VaR для такого портфеля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(altcoins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = altcoins.copy()\n",
    "stocks.append('BTC')\n",
    "print(stocks)\n",
    "numAssets = len(stocks)\n",
    "\n",
    "# доли активов в пакете\n",
    "weights = []\n",
    "for i in range(0,numAssets):\n",
    "    weights.append(1/numAssets)\n",
    "print(weights,\"\\n\")\n",
    "\n",
    "# данные по цене койнов за большой период времени\n",
    "data = combined_df.dropna()\n",
    "#data = data.loc['2018-2-1':'2018-8-1']\n",
    "# стоимости активов\n",
    "V = (data * weights).transpose().mean()\n",
    "print(\"Ininitial Inverstments \", round(sum(V[0]),1),\"$\")\n",
    "\n",
    "# колебания стоимости портфеля за период\n",
    "dailyReturn = V - V.shift(1)\n",
    "\n",
    "m = dailyReturn.mean()\n",
    "d = sqrt(dailyReturn.var())\n",
    "alpha = 3.715 # --> 0.01% случаев\n",
    "VaR = -(dailyReturn.mean() - alpha * d) # такой риск можно получить\n",
    "print(\"Mean Return\", m)\n",
    "print(\"Return Disp\", d)\n",
    "print(\"VAR \", VaR) # в долларах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(dailyReturn.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort the data:\n",
    "data_sorted = np.sort(dailyReturn)\n",
    "\n",
    "# calculate the proportional values of samples\n",
    "p = 1. * arange(len(dailyReturn)) / (len(dailyReturn) - 1)\n",
    "\n",
    "f = lambda x: np.interp(x, data_sorted, p)\n",
    "\n",
    "profit_prob = 100* (1 - f(0))\n",
    "risk = (1 - f(VaR)) * 100\n",
    "print(\"expected_profit = \", round(m,1),\"$\")\n",
    "print(\"profit > 0: \", round(profit_prob,1),\"%\")\n",
    "print(\"VaR > \", round(VaR,1), \"$: \", round(risk,1),\"%\") # более точное значение вероятности риска\n",
    "print(\"Ininitial Inverstments \", round(sum(V[0]),1),\"$\")\n",
    "print(\"Profit Persent \", round(100*m/sum(V[0]),1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эти величины показывают, сколько прибыли или убытков можно получить с вложений в портфель заданной стоимости. К примеру банковский процент по вкладам альфа-банка сейчас 2.5% при вложении денег на год, что более выгодно и надёжно, т.к. защищено страховыми обязательствами в случае банкротства банка. Но при этом например нельзя снимать деньги в течении года. Риски кажутся весьма высокими... Допустим ситуацию, когда мы имеем прибыль в течении 100 дней получаем.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*round(m,1),\"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весьма вероятна ситуация, когда мы можем на следующий день потерять величину большую VaR и убытки могут составить более чем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(VaR - 100 * m,1),\"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(100*round(VaR - 100 * m,1)/round(sum(V[0]),1),1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От первоначальных вложений... В принципе не так уж и опасно, но люди пишут, по идее нужно правило 10 * VaR (очень сомневаюсь что это правило действительно используется в наших реалиях)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stocks = altcoins.copy()\n",
    "stocks.append('BTC')\n",
    "numAssets = len(stocks)\n",
    "\n",
    "\n",
    "\n",
    "def get_VaR(cointypes, weights, combined_df):\n",
    "    # данные по цене койнов за большой период времени\n",
    "    data = combined_df.dropna()\n",
    "    #data = data.loc['2018-2-1':'2018-8-1']\n",
    "    # стоимости активов\n",
    "    V = (data * weights).transpose().mean()\n",
    "\n",
    "    # колебания стоимости портфеля за период\n",
    "    dailyReturn = V - V.shift(1)\n",
    "\n",
    "    m = dailyReturn.mean()\n",
    "    d = sqrt(dailyReturn.var())\n",
    "    alpha = 3.715 # --> 0.01% случаев\n",
    "    VaR = -(dailyReturn.mean() - alpha * d) # такой риск можно получить\n",
    "    return VaR\n",
    "\n",
    "\n",
    "for i in range(0,numAssets):\n",
    "# доли активов в пакете\n",
    "    weights = []\n",
    "    for j in range(0,numAssets):\n",
    "        value = 0\n",
    "        if(i == j):\n",
    "            value = 1\n",
    "        weights.append(value)\n",
    "    print(stocks[i],round(get_VaR(stocks, weights, combined_df),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VaRs = [[\"ETH\", 10.42],\n",
    "[\"LTC\", 2.83],\n",
    "[\"XRP\", 0.02],\n",
    "[\"ETC\", 0.47],\n",
    "[\"STR\", 0.01],\n",
    "[\"DASH\", 10.22],\n",
    "[\"SC\", 0.0],\n",
    "[\"XMR\", 4.04],\n",
    "[\"XEM\", 0.01],\n",
    "[\"BTC\", 126.8]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XEM - нет совсем\n",
    "XRP - нет совсем\n",
    "LTC - мало инфы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f = open('coin_herfindal.csv', 'r')\n",
    "\n",
    "raws = []\n",
    "with f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        raws.append(row)\n",
    "            \n",
    "currs = []\n",
    "varss = []\n",
    "herfs = []\n",
    "for i in range(0,len(VaRs)):\n",
    "    for j in range(0,len(raws)):\n",
    "        if(raws[j][0] == VaRs[i][0]):\n",
    "            currs.append(VaRs[i][0])\n",
    "            varss.append(float(VaRs[i][1]))\n",
    "            herfs.append(float(raws[j][1]))\n",
    "            break\n",
    "            \n",
    "            \n",
    "def mean(someList):\n",
    "    total = 0\n",
    "    for a in someList:\n",
    "        total += float(a)\n",
    "    mean = total/len(someList)\n",
    "    return mean\n",
    "def standDev(someList):\n",
    "    listMean = mean(someList)\n",
    "    dev = 0.0\n",
    "    for i in range(len(someList)):\n",
    "        dev += (someList[i]-listMean)**2\n",
    "    dev = dev**(1/2.0)\n",
    "    return dev\n",
    "def correlCo(someList1, someList2):\n",
    "\n",
    "    # First establish the means and standard deviations for both lists.\n",
    "    xMean = mean(someList1)\n",
    "    yMean = mean(someList2)\n",
    "    xStandDev = standDev(someList1)\n",
    "    yStandDev = standDev(someList2)\n",
    "    # r numerator\n",
    "    rNum = 0.0\n",
    "    for i in range(len(someList1)):\n",
    "        rNum += (someList1[i]-xMean)*(someList2[i]-yMean)\n",
    "\n",
    "    # r denominator\n",
    "    rDen = xStandDev * yStandDev\n",
    "\n",
    "    r =  rNum/rDen\n",
    "    return r\n",
    "\n",
    "\n",
    "print(currs)\n",
    "print(correlCo(varss,herfs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
